---
title: '232. From Typewriters to Transformers: AI is Just the Next Tools Abstraction'
date: '2025-06-24T22:20:41+08:00'
updated: '2025-05-31T04:15:12+08:00'
taxonomies:
  tags: null
extra:
  source: https://hardcoresoftware.learningbyshipping.com/p/232-from-typewriters-to-transformers
  hostname: learningbyshipping.com
  author: Steven Sinofsky
  original_title: '232. From Typewriters to Transformers: AI is Just the Next Tools
    Abstraction'
  original_lang: en
---

> **摘要**:
>  本文探讨了人工智能（AI）作为工具驱动的革命，解析了人们因其速度和新颖性而产生的恐惧与拒绝情绪。作者引用Freeman Dyson的观点，强调科学革命往往由新工具驱动，而AI正是如此。AI作为一个新范式，迅速被普及并应用于数百万用户，引发了一系列对于学习、写作以及传统教育的担忧。通过回顾打字机和计算器等历史工具的采用过程，作者指出新工具引入时的反对声音并不新鲜，历史上相似的担忧总是伴随变革而来。AI作为又一抽象层次，取消了人们对基本技能的依赖，从而带来了极大的效率提升。尽管对AI在教育中的应用难免存在争议，其实质更多是对变化的抵触，而非对AI本身的真实担忧。文章强调，AI的引入意味着未来的不可逆转，教育工作者和社会需要适应这种变革，而不是盲目恐惧。
> 
>  **要点总结**:
>  1. AI是工具驱动的革命，带来了科学革命的新范式。
>  2. 传统工具如打字机和计算器的采用过程中，历史上出现过类似的恐惧和反对情绪。
>  3. AI的普及带来新的抽象层次，使人们在学习与工作中更加高效，而不再依赖基本技能。
>  4. 对AI的批评往往是对变化的抵触，而非对其本质的真实担忧。
>  5. AI已经融入现实生活，社会应积极适应这一变革，而非抵制。

---


### AI is a tool-driven revolution. That’s why it unnerves people. Freeman Dyson said in 1993, “Scientific revolutions are more often driven by new tools than by new concepts.” That’s AI.

AI is a tool-driven revolution. That’s why it unnerves people. Freeman Dyson said in 1993, “Scientific revolutions are more often driven by new tools than by new concepts.” That’s AI.

For those deep in tech, AI is clearly a new paradigm—a sweeping theorem of software. Most paradigm shifts *precede* new tools. But with AI, we fast-forwarded: from paradigm to tools in under a decade, now used by hundreds of millions. That speed doesn’t soften the typical reaction to new tools—fear, skepticism, even rejection. We’ve seen this with every major shift in computing. This post shares a few examples of that resistance in action.

![Image](https://substackcdn.com/image/fetch/$s_!vYLM!)

This is an article from Physics World reproduced in Science magazine. As I was in the business of making tools it so resonated with me I had it pinned to my Microsoft cork board for decades....

On Bari Weiss’ *Honestly* podcast, a recent debate tackled: [Will the Truth Survive Artificial Intelligence?](https://podcasts.apple.com/us/podcast/honestly-with-bari-weiss/id1570872415?i=1000709403982)

The “yes” side featured Aravind Srinivas (Perplexity) and Fei-Fei Li (Stanford); the “no” side, Jaron Lanier (Microsoft) and Nicholas Carr. I won’t spoil the debate, but a major theme was concern about learning, writing, and education.

AI is a tool. Tools abstract and automate tasks. Each new one adds abstraction and automation over what came before. That’s rarely controversial—until it touches something people are emotionally or professionally invested in.

Case in point: teachers once opposed typewriters in class. They worried students would forget how to write. They were right—by college, I could barely write cursive. But typing papers was faster and easier to grade. Teachers opposed calculators for fear of failing to add. But now engineers skip the slide rule and get vastly more done with libraries of routines and more.

My freshman year (1983) was a turning point. Two quick stories:

**First:** Most students arrived with typewriters—graduation gifts. You were expected to turn in typed papers. Rich kids had “fancy” models that let you backspace before a line was committed to paper.

Meanwhile, the university had a few WANG word processors—business-grade machines—available to select writing sections. Faculty were worried: if students didn’t handwrite first drafts, would they learn to write at all? That exact fear came up in the podcast too.

So we ran an experiment. Most students used pen and paper, then typed. A few of us used WANG machines for everything. Faculty planned to compare the results.

Then came January 1984. Macintosh launched. Apple pushed them onto campuses. What the faculty hoped to study was rendered moot overnight. The tool leapfrogged the debate—just like GPT did two years ago.

The real issue wasn’t just speed. It was abstraction. Word processors offloaded spell check, formatting, and editing—freeing us to focus on content. Educators already complained about poor spelling *before* grammar checkers showed up.

**Second:** I was a computer science major. CS was a new discipline then—separated from electrical engineering in the 1960s. Its foundation? Abstraction: you didn’t need to solder circuits to build software.

This wasn’t universally accepted. Many schools kept CS under engineering, requiring EE and physics. That meant you still learned transistors to write code. My school dropped that. We were among the first CS majors who didn’t take physics or EE—and some argued we’d never truly understand computers.

They were wrong. That too was an abstraction.

**AI is the next abstraction layer.**

And like all previous abstractions, it’s criticized on two fronts:

- **Loss of fundamentals:** New users won’t understand what came before. That’s true. But also true: they can do *far more* than previous generations. Abstraction is about *not needing* the old tricks. No one misses manually hyphenating or footnoting on a typewriter.
- **Lack of understanding:** Critics say people won’t know how their AI-generated results were made. That’s a weak argument. When a carpenter uses a nail gun, do we say they no longer understand roofing? I know what my computer is doing even if I’m not flipping bits manually.

So why the negativity around AI in learning? Is it just a replay of new technology in schools?

It’s not unique or new. People say students will get lazy, not “really” understand, or miss what “matters.” The same was said about word processors. And Macs. And dropping EE courses.

Growing up, we were drilled on how to find things in the library—but never allowed to use the encyclopedia. That was “cheating.” Odd, since many families invested in full encyclopedia sets.

Then I discovered the *almanac*. Game over. I won every classroom research contest using that book. We bought a new edition every year. It felt obvious. That instinct is why my dad bought an early PC. My first thought going online? “Now I’ve got a real-time almanac—at 300 baud.”

What we hear today about AI—worries about truth, AGI, or education—isn’t really about those things. They’re dressed-up ways of resisting change.

Writing and learning with AI is the typewriter, the word processor, the encyclopedia, and the almanac rolled into one. Seeing it as something scarier than that is just fear of new tools and new paradigms. Again. It is not surprise that we're seeing so much writing about concerns—writers are the ones who are directly challenged. Just as electrical engineers were challenged by software abstracting out hardware.

Some will say not all abstraction layers are created equally. Not all tools are “harmless”. And they would conclude if they believe that about AI that AI needs more scrutiny sooner and that we should slow down before we understand. The challenge is the future doesn’t just wait around for everyone to come to a consensus. It arrives with new tools in hand. That’s what happened in 1984 when Macintosh arrived. That’s what is happening with AI.

AI is here. It’s already happening.