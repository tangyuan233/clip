---
title: '232. From Typewriters to Transformers: AI is Just the Next Tools Abstraction'
date: '2025-06-24T22:20:41+08:00'
updated: '2025-05-31T04:15:12+08:00'
taxonomies:
  tags: null
extra:
  source: https://hardcoresoftware.learningbyshipping.com/p/232-from-typewriters-to-transformers
  hostname: learningbyshipping.com
  author: Steven Sinofsky
  original_title: '232. From Typewriters to Transformers: AI is Just the Next Tools
    Abstraction'
  original_lang: en
---

> **摘要**:
>  本文探讨了人工智能（AI）作为工具驱动革命的特性，强调其速度和影响力使得人们产生了恐惧和怀疑。作者引用Freeman Dyson的话指出，科学革命往往由新工具驱动，而AI在不到十年的时间内迅速从理念转化为被广泛使用的工具。文章通过历史典故，说明教育界对新工具的抵制，如教师对打字机和计算器的反对，指出这种抵制源于对教育和写作方式的情感和职业投资。AI被视为下一个抽象层次，引发对基础知识和理解能力丧失的担忧。作者反驳这些观点，认为新工具的诞生意味着人们能够更高效地完成任务，且不需要因此完全理解工具的内部运作。AI在写作和学习中被比作打字机和百科全书的结合，阻碍其发展的顾虑实际上是对变革的抵抗。最后，作者指出AI已然到来，并将持续影响我们的未来。
> 
>  **要点总结**:
>  1. AI是工具驱动的革命，它的快速发展引发了公众的恐惧和怀疑。
>  2. 历史上，类似新技术（如打字机、计算器）都有遇到抵制，尤其在教育领域。
>  3. AI被视为新的抽象层，导致对基础知识缺乏理解的担忧，但实际上人们可以更高效地完成任务。
>  4. 人们对AI的负面看法多源于对变化的抵抗，而非真正的技术担忧。
>  5. AI的影响已在各个领域显现，它将持续引领未来发展。

---


### AI is a tool-driven revolution. That’s why it unnerves people. Freeman Dyson said in 1993, “Scientific revolutions are more often driven by new tools than by new concepts.” That’s AI.

AI is a tool-driven revolution. That’s why it unnerves people. Freeman Dyson said in 1993, “Scientific revolutions are more often driven by new tools than by new concepts.” That’s AI.

For those deep in tech, AI is clearly a new paradigm—a sweeping theorem of software. Most paradigm shifts *precede* new tools. But with AI, we fast-forwarded: from paradigm to tools in under a decade, now used by hundreds of millions. That speed doesn’t soften the typical reaction to new tools—fear, skepticism, even rejection. We’ve seen this with every major shift in computing. This post shares a few examples of that resistance in action.

![Image](https://substackcdn.com/image/fetch/$s_!vYLM!)

This is an article from Physics World reproduced in Science magazine. As I was in the business of making tools it so resonated with me I had it pinned to my Microsoft cork board for decades....

On Bari Weiss’ *Honestly* podcast, a recent debate tackled: [Will the Truth Survive Artificial Intelligence?](https://podcasts.apple.com/us/podcast/honestly-with-bari-weiss/id1570872415?i=1000709403982)

The “yes” side featured Aravind Srinivas (Perplexity) and Fei-Fei Li (Stanford); the “no” side, Jaron Lanier (Microsoft) and Nicholas Carr. I won’t spoil the debate, but a major theme was concern about learning, writing, and education.

AI is a tool. Tools abstract and automate tasks. Each new one adds abstraction and automation over what came before. That’s rarely controversial—until it touches something people are emotionally or professionally invested in.

Case in point: teachers once opposed typewriters in class. They worried students would forget how to write. They were right—by college, I could barely write cursive. But typing papers was faster and easier to grade. Teachers opposed calculators for fear of failing to add. But now engineers skip the slide rule and get vastly more done with libraries of routines and more.

My freshman year (1983) was a turning point. Two quick stories:

**First:** Most students arrived with typewriters—graduation gifts. You were expected to turn in typed papers. Rich kids had “fancy” models that let you backspace before a line was committed to paper.

Meanwhile, the university had a few WANG word processors—business-grade machines—available to select writing sections. Faculty were worried: if students didn’t handwrite first drafts, would they learn to write at all? That exact fear came up in the podcast too.

So we ran an experiment. Most students used pen and paper, then typed. A few of us used WANG machines for everything. Faculty planned to compare the results.

Then came January 1984. Macintosh launched. Apple pushed them onto campuses. What the faculty hoped to study was rendered moot overnight. The tool leapfrogged the debate—just like GPT did two years ago.

The real issue wasn’t just speed. It was abstraction. Word processors offloaded spell check, formatting, and editing—freeing us to focus on content. Educators already complained about poor spelling *before* grammar checkers showed up.

**Second:** I was a computer science major. CS was a new discipline then—separated from electrical engineering in the 1960s. Its foundation? Abstraction: you didn’t need to solder circuits to build software.

This wasn’t universally accepted. Many schools kept CS under engineering, requiring EE and physics. That meant you still learned transistors to write code. My school dropped that. We were among the first CS majors who didn’t take physics or EE—and some argued we’d never truly understand computers.

They were wrong. That too was an abstraction.

**AI is the next abstraction layer.**

And like all previous abstractions, it’s criticized on two fronts:

- **Loss of fundamentals:** New users won’t understand what came before. That’s true. But also true: they can do *far more* than previous generations. Abstraction is about *not needing* the old tricks. No one misses manually hyphenating or footnoting on a typewriter.
- **Lack of understanding:** Critics say people won’t know how their AI-generated results were made. That’s a weak argument. When a carpenter uses a nail gun, do we say they no longer understand roofing? I know what my computer is doing even if I’m not flipping bits manually.

So why the negativity around AI in learning? Is it just a replay of new technology in schools?

It’s not unique or new. People say students will get lazy, not “really” understand, or miss what “matters.” The same was said about word processors. And Macs. And dropping EE courses.

Growing up, we were drilled on how to find things in the library—but never allowed to use the encyclopedia. That was “cheating.” Odd, since many families invested in full encyclopedia sets.

Then I discovered the *almanac*. Game over. I won every classroom research contest using that book. We bought a new edition every year. It felt obvious. That instinct is why my dad bought an early PC. My first thought going online? “Now I’ve got a real-time almanac—at 300 baud.”

What we hear today about AI—worries about truth, AGI, or education—isn’t really about those things. They’re dressed-up ways of resisting change.

Writing and learning with AI is the typewriter, the word processor, the encyclopedia, and the almanac rolled into one. Seeing it as something scarier than that is just fear of new tools and new paradigms. Again. It is not surprise that we're seeing so much writing about concerns—writers are the ones who are directly challenged. Just as electrical engineers were challenged by software abstracting out hardware.

Some will say not all abstraction layers are created equally. Not all tools are “harmless”. And they would conclude if they believe that about AI that AI needs more scrutiny sooner and that we should slow down before we understand. The challenge is the future doesn’t just wait around for everyone to come to a consensus. It arrives with new tools in hand. That’s what happened in 1984 when Macintosh arrived. That’s what is happening with AI.

AI is here. It’s already happening.