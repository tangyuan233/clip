---
title: '232. From Typewriters to Transformers: AI is Just the Next Tools Abstraction'
date: '2025-06-24T22:20:41+08:00'
updated: '2025-05-31T04:15:12+08:00'
taxonomies:
  tags: null
extra:
  source: https://hardcoresoftware.learningbyshipping.com/p/232-from-typewriters-to-transformers
  hostname: learningbyshipping.com
  author: Steven Sinofsky
  original_title: '232. From Typewriters to Transformers: AI is Just the Next Tools
    Abstraction'
  original_lang: en
---

> **摘要**:
>  文章指出人工智能（AI）是一场由工具驱动的革命，其发展速度之快使人们感到不安。引用弗里曼·戴森的观点，科学革命往往由新工具驱动而非新概念，AI即是如此。AI的出现被视为一次范式转变，迅速渗透到数亿人日常生活中。文章通过历史案例，如打字机、计算器等，阐述了人们对新工具的抗拒心理。作者提到AI的抽象化特性使得用户不再需要掌握旧有技能，但也让人担忧是否会失去对基础知识的理解。这种对新技术的恐惧并非新鲜事物，历史上对于每一项技术的质疑都循环出现。最终，AI技术的不可逆转发展提醒人们，随着新工具的出现，教育和学习的方式必将变革。
> 
>  **要点总结**:
>  1. 人工智能的革命是由工具驱动的，发展速度让人们感到不安。
>  2. AI的出现标志着一种新的范式转变，迅速被广泛应用。
>  3. 历史表明，人们对新工具的抵抗情绪是常见的，比如曾经对打字机和计算器的担忧。
>  4. AI的抽象化可能导致用户对传统技能的依赖减少，引发对基本知识理解的担忧。
>  5. 对新技术的恐惧并不是新现象，教育和学习方式的变革是不可避免的。

---


### AI is a tool-driven revolution. That’s why it unnerves people. Freeman Dyson said in 1993, “Scientific revolutions are more often driven by new tools than by new concepts.” That’s AI.

AI is a tool-driven revolution. That’s why it unnerves people. Freeman Dyson said in 1993, “Scientific revolutions are more often driven by new tools than by new concepts.” That’s AI.

For those deep in tech, AI is clearly a new paradigm—a sweeping theorem of software. Most paradigm shifts *precede* new tools. But with AI, we fast-forwarded: from paradigm to tools in under a decade, now used by hundreds of millions. That speed doesn’t soften the typical reaction to new tools—fear, skepticism, even rejection. We’ve seen this with every major shift in computing. This post shares a few examples of that resistance in action.

![Image](https://substackcdn.com/image/fetch/$s_!vYLM!)

This is an article from Physics World reproduced in Science magazine. As I was in the business of making tools it so resonated with me I had it pinned to my Microsoft cork board for decades....

On Bari Weiss’ *Honestly* podcast, a recent debate tackled: [Will the Truth Survive Artificial Intelligence?](https://podcasts.apple.com/us/podcast/honestly-with-bari-weiss/id1570872415?i=1000709403982)

The “yes” side featured Aravind Srinivas (Perplexity) and Fei-Fei Li (Stanford); the “no” side, Jaron Lanier (Microsoft) and Nicholas Carr. I won’t spoil the debate, but a major theme was concern about learning, writing, and education.

AI is a tool. Tools abstract and automate tasks. Each new one adds abstraction and automation over what came before. That’s rarely controversial—until it touches something people are emotionally or professionally invested in.

Case in point: teachers once opposed typewriters in class. They worried students would forget how to write. They were right—by college, I could barely write cursive. But typing papers was faster and easier to grade. Teachers opposed calculators for fear of failing to add. But now engineers skip the slide rule and get vastly more done with libraries of routines and more.

My freshman year (1983) was a turning point. Two quick stories:

**First:** Most students arrived with typewriters—graduation gifts. You were expected to turn in typed papers. Rich kids had “fancy” models that let you backspace before a line was committed to paper.

Meanwhile, the university had a few WANG word processors—business-grade machines—available to select writing sections. Faculty were worried: if students didn’t handwrite first drafts, would they learn to write at all? That exact fear came up in the podcast too.

So we ran an experiment. Most students used pen and paper, then typed. A few of us used WANG machines for everything. Faculty planned to compare the results.

Then came January 1984. Macintosh launched. Apple pushed them onto campuses. What the faculty hoped to study was rendered moot overnight. The tool leapfrogged the debate—just like GPT did two years ago.

The real issue wasn’t just speed. It was abstraction. Word processors offloaded spell check, formatting, and editing—freeing us to focus on content. Educators already complained about poor spelling *before* grammar checkers showed up.

**Second:** I was a computer science major. CS was a new discipline then—separated from electrical engineering in the 1960s. Its foundation? Abstraction: you didn’t need to solder circuits to build software.

This wasn’t universally accepted. Many schools kept CS under engineering, requiring EE and physics. That meant you still learned transistors to write code. My school dropped that. We were among the first CS majors who didn’t take physics or EE—and some argued we’d never truly understand computers.

They were wrong. That too was an abstraction.

**AI is the next abstraction layer.**

And like all previous abstractions, it’s criticized on two fronts:

- **Loss of fundamentals:** New users won’t understand what came before. That’s true. But also true: they can do *far more* than previous generations. Abstraction is about *not needing* the old tricks. No one misses manually hyphenating or footnoting on a typewriter.
- **Lack of understanding:** Critics say people won’t know how their AI-generated results were made. That’s a weak argument. When a carpenter uses a nail gun, do we say they no longer understand roofing? I know what my computer is doing even if I’m not flipping bits manually.

So why the negativity around AI in learning? Is it just a replay of new technology in schools?

It’s not unique or new. People say students will get lazy, not “really” understand, or miss what “matters.” The same was said about word processors. And Macs. And dropping EE courses.

Growing up, we were drilled on how to find things in the library—but never allowed to use the encyclopedia. That was “cheating.” Odd, since many families invested in full encyclopedia sets.

Then I discovered the *almanac*. Game over. I won every classroom research contest using that book. We bought a new edition every year. It felt obvious. That instinct is why my dad bought an early PC. My first thought going online? “Now I’ve got a real-time almanac—at 300 baud.”

What we hear today about AI—worries about truth, AGI, or education—isn’t really about those things. They’re dressed-up ways of resisting change.

Writing and learning with AI is the typewriter, the word processor, the encyclopedia, and the almanac rolled into one. Seeing it as something scarier than that is just fear of new tools and new paradigms. Again. It is not surprise that we're seeing so much writing about concerns—writers are the ones who are directly challenged. Just as electrical engineers were challenged by software abstracting out hardware.

Some will say not all abstraction layers are created equally. Not all tools are “harmless”. And they would conclude if they believe that about AI that AI needs more scrutiny sooner and that we should slow down before we understand. The challenge is the future doesn’t just wait around for everyone to come to a consensus. It arrives with new tools in hand. That’s what happened in 1984 when Macintosh arrived. That’s what is happening with AI.

AI is here. It’s already happening.